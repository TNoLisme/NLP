{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-21T23:41:55.658100Z",
     "iopub.status.busy": "2025-12-21T23:41:55.657813Z",
     "iopub.status.idle": "2025-12-21T23:41:59.430497Z",
     "shell.execute_reply": "2025-12-21T23:41:59.429842Z",
     "shell.execute_reply.started": "2025-12-21T23:41:55.658072Z"
    },
    "trusted": true
   },
   "source": [
    "CHECK VERSION GPU KAGGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Machine Translation - VLSP 2025\n",
    "\n",
    "## 1. Kiểm tra môi trường và cấu hình GPU\n",
    "\n",
    "Trước khi bắt đầu, chúng ta kiểm tra cấu hình phần cứng (GPU Tesla T4) và các thư viện deep learning (PyTorch, CUDA) để đảm bảo môi trường phù hợp cho việc huấn luyện mô hình ngôn ngữ lớn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"===== GPU =====\")\n",
    "print(subprocess.getoutput(\"nvidia-smi\"))\n",
    "\n",
    "print(\"\\n===== CUDA Torch =====\")\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cài đặt thư viện\n",
    "\n",
    "### 2.1. Gỡ các phiên bản cũ\n",
    "Để tránh xung đột phiên bản, chúng ta gỡ bỏ các thư viện cũ trước khi cài đặt phiên bản tương thích với Qwen2.5-3B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -q -y transformers accelerate peft trl bitsandbytes unsloth unsloth-zoo protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Cài đặt Dependencies chính\n",
    "\n",
    "Cài đặt các thư viện cốt lõi:\n",
    "- **transformers**: Thư viện Hugging Face để load mô hình Qwen2.5\n",
    "- **peft**: Parameter-Efficient Fine-Tuning (LoRA)\n",
    "- **trl**: Trainer cho Supervised Fine-Tuning\n",
    "- **sacrebleu**: Đánh giá chất lượng dịch thuật\n",
    "- **sentence-transformers**: Xử lý embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --no-cache-dir \\\n",
    "    \"protobuf==3.20.3\" \\\n",
    "    \"transformers==4.57.3\" \\\n",
    "    \"accelerate==1.12.0\" \\\n",
    "    \"peft==0.13.2\" \\\n",
    "    \"trl==0.24.0\" \\\n",
    "    \"datasets>=2.13.0\" \\\n",
    "    \"safetensors\" \\\n",
    "    \"sentencepiece\" \\\n",
    "    \"huggingface-hub\" \\\n",
    "    \"evaluate\" \\\n",
    "    \"sacrebleu\" \\\n",
    "    \"sentence-transformers\"\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Mô hình và Tokenizer\n",
    "\n",
    "### Mô hình cơ sở: Qwen2.5-3B-Instruct\n",
    "Mô hình cơ sở có 3 tỷ tham số, được huấn luyện sẵn với khả năng:\n",
    "- Đa ngôn ngữ (bao gồm tiếng Việt)\n",
    "- Tuân thủ chỉ dẫn (Instruction Following)\n",
    "- Cửa sổ ngữ cảnh 32K tokens\n",
    "\n",
    "**Lưu ý**: Nhóm **KHÔNG** sử dụng quantization (4-bit/8-bit) để bảo toàn năng lực hiểu ngữ nghĩa y khoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    dtype=\"auto\",              \n",
    "    trust_remote_code=True,\n",
    "    quantization_config=None,\n",
    ")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chuẩn bị và phân tích dữ liệu\n",
    "\n",
    "### 4.1. Load dữ liệu Thô\n",
    "Tập dữ liệu VLSP Medical bao gồm:\n",
    "- **Train**: 500,000 cặp câu song ngữ Anh-Việt\n",
    "- **Public Test**: 3,000 cặp câu\n",
    "\n",
    "Dữ liệu chứa các thuật ngữ y khoa phức tạp như tên thuốc, bệnh lý, chỉ định lâm sàng và từ viết tắt chuyên ngành."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/medical-data\"\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "def read_file(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "print(\"Loading raw text files...\")\n",
    "train_en = read_file(os.path.join(DATA_DIR, \"train.en.txt\"))\n",
    "train_vi = read_file(os.path.join(DATA_DIR, \"train.vi.txt\"))\n",
    "test_en = read_file(os.path.join(DATA_DIR, \"public_test.en.txt\"))\n",
    "test_vi = read_file(os.path.join(DATA_DIR, \"public_test.vi.txt\"))\n",
    "\n",
    "assert len(train_en) == len(train_vi)\n",
    "print(f\"Successfully loaded {len(train_en)} training pairs and {len(test_en)} test pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Phân tích thống kê và nhận diện nhiễu\n",
    "\n",
    "#### Mục tiêu:\n",
    "- Phân tích phân bổ độ dài câu\n",
    "- Nhận diện các từ viết tắt y khoa (Medical Abbreviations)\n",
    "- Phát hiện dữ liệu ngoại lai (outliers) do lỗi phân đoạn văn bản\n",
    "\n",
    "#### Kết quả quan sát:\n",
    "- Độ dài trung bình: ~21 từ (EN), ~30 từ (VI)\n",
    "- Độ dài cực đại: 477 từ (EN), 519 từ (VI) → **Dữ liệu nhiễu**\n",
    "- Hàng ngàn thuật ngữ viết tắt: CT, MRI, HIV, ĐTĐ, BN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROMAN_NUMERALS = {'II', 'III', 'IV', 'VI', 'VII', 'VIII', 'IX', 'X', 'XI', 'XII'}\n",
    "\n",
    "def analyze_stats_pro(data_list):\n",
    "    lengths = [len(sentence.split()) for sentence in data_list]\n",
    "    abbs = []\n",
    "    for sentence in data_list:\n",
    "        clean_sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        words = clean_sentence.split()\n",
    "        for w in words:\n",
    "            if w.isupper() and len(w) >= 2 and not w.isdigit():\n",
    "                if w not in ROMAN_NUMERALS:\n",
    "                    abbs.append(w)\n",
    "    return lengths, abbs\n",
    "\n",
    "# --- Execution ---\n",
    "print(\"Analyzing Original Dataset Statistics...\")\n",
    "en_lengths_orig, en_abbs_orig = analyze_stats_pro(train_en)\n",
    "vi_lengths_orig, vi_abbs_orig = analyze_stats_pro(train_vi)\n",
    "\n",
    "# Stats Table\n",
    "summary_orig = pd.DataFrame({\n",
    "    \"Metrics\": [\"Total Sentences\", \"Average Length (words)\", \"Max Length (words)\", \"Unique Abbreviations\"],\n",
    "    \"English Corpus\": [len(train_en), f\"{np.mean(en_lengths_orig):.2f}\", np.max(en_lengths_orig), len(set(en_abbs_orig))],\n",
    "    \"Vietnamese Corpus\": [len(train_vi), f\"{np.mean(vi_lengths_orig):.2f}\", np.max(vi_lengths_orig), len(set(vi_abbs_orig))]\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY OF ORIGINAL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(summary_orig.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Chart 1: Sentence Length Distribution (Original)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(vi_lengths_orig, color=\"#3498db\", label=\"Vietnamese\", kde=True, binrange=(0, 140), alpha=0.6)\n",
    "sns.histplot(en_lengths_orig, color=\"#e74c3c\", label=\"English\", kde=True, binrange=(0, 100), alpha=0.4)\n",
    "plt.title(\"Original Sentence Length Distribution\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlim(0, 150)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Helper Function for Abbreviation Charts\n",
    "def plot_medical_abbs(abbs, title, palette, filename):\n",
    "    top_abbs = Counter(abbs).most_common(15)\n",
    "    words, counts = zip(*top_abbs)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    ax = sns.barplot(x=list(words), y=list(counts), palette=palette, hue=list(words), legend=False)\n",
    "    \n",
    "    # Add exact counts on top of bars\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', \n",
    "                    (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha = 'center', va = 'center', \n",
    "                    xytext = (0, 9), \n",
    "                    textcoords = 'offset points',\n",
    "                    fontsize=10)\n",
    "\n",
    "    plt.title(title, fontsize=15, fontweight='bold')\n",
    "    plt.xlabel(\"Abbreviations\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Chart 2 & 3: Original Medical Abbreviations\n",
    "print(\"Generating Original Abbreviation Charts...\")\n",
    "plot_medical_abbs(vi_abbs_orig, \"Top 15 Medical Abbreviations (Original VI Dataset)\", \"viridis\", \"orig_vi_abbs.png\")\n",
    "plot_medical_abbs(en_abbs_orig, \"Top 15 Medical Abbreviations (Original EN Dataset)\", \"magma\", \"orig_en_abbs.png\")\n",
    "\n",
    "# Outlier Identification (Noise detection)\n",
    "max_vi_idx = np.argmax(vi_lengths_orig)\n",
    "max_en_idx = np.argmax(en_lengths_orig)\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(f\"DEBUG: Longest VI Sample ({vi_lengths_orig[max_vi_idx]} words):\")\n",
    "print(f\"{train_vi[max_vi_idx][:300]}...\") \n",
    "print(f\"\\nDEBUG: Longest EN Sample ({en_lengths_orig[max_en_idx]} words):\")\n",
    "print(f\"{train_en[max_en_idx][:300]}...\")\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Làm sạch dữ liệu\n",
    "\n",
    "#### Chiến lược lọc:\n",
    "Áp dụng ngưỡng **180 từ tổng** (EN + VI) cho mỗi cặp câu để:\n",
    "- Đảm bảo toàn bộ prompt + dịch < 512 tokens (giới hạn của Qwen2.5)\n",
    "- Tránh cắt cụt (truncation) gây mất thông tin y khoa quan trọng\n",
    "- Loại bỏ các đoạn văn bị dính chùm do lỗi segmentation\n",
    "\n",
    "#### Kết quả:\n",
    "- **Loại bỏ**: 4,360 cặp câu nhiễu (~0.87%)\n",
    "- **Giữ lại**: 495,640 cặp câu chất lượng cao\n",
    "- Độ dài cực đại giảm xuống: 126 từ (EN), 136 từ (VI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = [{\"en\": e, \"vi\": v} for e, v in zip(train_en, train_vi)]\n",
    "test_pairs = [{\"en\": e, \"vi\": v} for e, v in zip(test_en, test_vi)]\n",
    "\n",
    "# --- Làm sạch (Ngưỡng: tổng cộng 180 từ) ---\n",
    "# Điều này đảm bảo rằng (Câu hỏi + Nguồn + Mục tiêu) < 512 từ\n",
    "MAX_WORDS_TOTAL = 180 \n",
    "\n",
    "cleaned_pairs = [d for d in train_pairs if (len(d['en'].split()) + len(d['vi'].split())) < MAX_WORDS_TOTAL]\n",
    "\n",
    "print(f\"Original pairs count: {len(train_pairs)}\")\n",
    "print(f\"Cleaned pairs count:  {len(cleaned_pairs)}\")\n",
    "print(f\"Pruned {len(train_pairs) - len(cleaned_pairs)} noisy/oversized sequences.\")\n",
    "\n",
    "# --- Split After Cleaning ---\n",
    "train_split, valid_split = train_test_split(\n",
    "    cleaned_pairs, \n",
    "    test_size=0.05, \n",
    "    random_state=42, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# --- Create Final DatasetDict ---\n",
    "raw_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_list(train_split),\n",
    "    \"validation\": Dataset.from_list(valid_split),\n",
    "    \"test\": Dataset.from_list(test_pairs),\n",
    "})\n",
    "\n",
    "print(f\"\\nDataset Construction Completed:\")\n",
    "print(f\"- Final Train size: {len(train_split)}\")\n",
    "print(f\"- Final Valid size: {len(valid_split)}\")\n",
    "print(f\"- Final Test size:  {len(test_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Phân tích sau làm sạch\n",
    "\n",
    "So sánh phân bổ dữ liệu và mật độ thuật ngữ y khoa **trước và sau** khi làm sạch:\n",
    "- Phân bổ độ dài câu trở nên tập trung hơn (10-40 từ)\n",
    "- Các thuật ngữ cốt lõi được bảo toàn hoàn toàn\n",
    "- Loại bỏ hoàn toàn hiện tượng \"đuôi dài\" (long tail) gây nhiễu huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_medical_abbs(abbs, title, palette, filename):\n",
    "    top_abbs = Counter(abbs).most_common(15)\n",
    "    words, counts = zip(*top_abbs)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    ax = sns.barplot(x=list(words), y=list(counts), palette=palette, hue=list(words), legend=False)\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                    ha='center', va='center', xytext=(0, 9), textcoords='offset points', fontsize=10)\n",
    "    plt.title(title, fontsize=15, fontweight='bold')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "clean_train_en = [d['en'] for d in cleaned_pairs]\n",
    "clean_train_vi = [d['vi'] for d in cleaned_pairs]\n",
    "\n",
    "en_lengths_clean, en_abbs_clean = analyze_stats_pro(clean_train_en)\n",
    "vi_lengths_clean, vi_abbs_clean = analyze_stats_pro(clean_train_vi)\n",
    "\n",
    "# Chart Cleaned Distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(vi_lengths_clean, color=\"#2ecc71\", label=\"Vietnamese (Cleaned)\", kde=True, alpha=0.6)\n",
    "sns.histplot(en_lengths_clean, color=\"#f39c12\", label=\"English (Cleaned)\", kde=True, alpha=0.4)\n",
    "plt.title(\"Cleaned Sentence Length Distribution (Safety Limit Applied)\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Charts Abbreviation analysis for Cleaned Data\n",
    "plot_medical_abbs(en_abbs_clean, \"Top 15 Medical Abbreviations (Cleaned EN Dataset)\", \"magma\", \"clean_en_abbs.png\")\n",
    "plot_medical_abbs(vi_abbs_clean, \"Top 15 Medical Abbreviations (Cleaned VI Dataset)\", \"viridis\", \"clean_vi_abbs.png\")\n",
    "\n",
    "# Final Comparison Table\n",
    "summary_clean = pd.DataFrame({\n",
    "    \"Metrics\": [\"Total Sentences\", \"Average Length (words)\", \"Max Length (words)\", \"Unique Abbreviations\"],\n",
    "    \"English (Cleaned)\": [len(clean_train_en), f\"{np.mean(en_lengths_clean):.2f}\", np.max(en_lengths_clean), len(set(en_abbs_clean))],\n",
    "    \"Vietnamese (Cleaned)\": [len(clean_train_vi), f\"{np.mean(vi_lengths_clean):.2f}\", np.max(vi_lengths_clean), len(set(vi_abbs_clean))]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SUMMARY OF CLEANED DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(summary_clean.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cấu hình hướng huấn luyện\n",
    "\n",
    "### Chiến lược đa chiều linh hoạt\n",
    "\n",
    "Thay vì huấn luyện một mô hình \"vạn năng\" cho cả hai chiều (dễ bị Task Interference), chúng ta huấn luyện **hai Adapter độc lập**:\n",
    "\n",
    "- **`TRAIN_DIRECTION = \"en_vi\"`**: Huấn luyện adapter chuyên dịch Anh → Việt\n",
    "- **`TRAIN_DIRECTION = \"vi_en\"`**: Huấn luyện adapter chuyên dịch Việt → Anh\n",
    "\n",
    "Mỗi adapter học sâu vào đặc trưng ngôn ngữ và thuật ngữ của một chiều duy nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn hướng: \"en_vi\" (Anh->Việt) hoặc \"vi_en\" (Việt->Anh)\n",
    "#TRAIN_DIRECTION = \"vi_en\"\n",
    "TRAIN_DIRECTION = \"en_vi\"\n",
    "print(f\"Chế độ Train: {TRAIN_DIRECTION.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Xây dựng Prompt Template\n",
    "\n",
    "#### Chuyển đổi dịch máy → hội thoại dẫn dắt\n",
    "\n",
    "Qwen2.5 là mô hình Decoder-only (không phải Encoder-Decoder như BART), do đó chúng ta sử dụng định dạng **ChatML** để biến bài toán dịch thuật thành bài toán Instruction Following:\n",
    "\n",
    "**Ví dụ với EN-VI:**\n",
    "```\n",
    "User: Dịch câu sau sang tiếng Việt:\n",
    "      <Câu tiếng Anh>\n",
    "Assistant: <Câu tiếng Việt>\n",
    "```\n",
    "\n",
    "Hàm `build_prompt()` tự động xây dựng prompt phù hợp dựa trên `TRAIN_DIRECTION` hiện tại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(src_text, tgt_text=None):\n",
    "    \"\"\"\n",
    "    Tạo prompt theo chuẩn chat của Qwen2.5:\n",
    "    - user: yêu cầu dịch dựa trên TRAIN_DIRECTION\n",
    "    - assistant: ground truth (tgt_text) nếu training\n",
    "    \"\"\"\n",
    "    # Xác định hướng và tạo prompt tương ứng\n",
    "    if TRAIN_DIRECTION == \"en_vi\":\n",
    "        user_content = f\"Dịch câu sau sang tiếng Việt:\\n{src_text}\"\n",
    "    else: # vi_en\n",
    "        user_content = f\"Dịch câu sau sang tiếng Anh:\\n{src_text}\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": user_content}]\n",
    "    \n",
    "    if tgt_text is not None:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": tgt_text})\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Đăng nhập Hugging Face Hub\n",
    "\n",
    "Cần thiết để:\n",
    "- Lưu trữ dữ liệu đã tokenize (Smart Caching)\n",
    "- Đẩy adapter lên cloud sau khi huấn luyện (Safe-Save Protocol)\n",
    "- Đảm bảo tính liên tục khi Kaggle Kernel khởi động lại\n",
    "- Lưu file được model dịch sau khi train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = \"token_login\" \n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "print(\">>> Login success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Tokenization và Smart Caching\n",
    "\n",
    "#### Quy trình:\n",
    "1. **Check**: Kiểm tra xem dữ liệu đã tokenize cho `TRAIN_DIRECTION` hiện tại có trên Hub chưa\n",
    "2. **Reuse**: Nếu có → Tải về và sử dụng trực tiếp (tiết kiệm quá trình tokenize lại)\n",
    "3. **Update**: Nếu chưa có → Tokenize toàn bộ dataset và đẩy lên Hub\n",
    "\n",
    "#### Kết quả Tokenization:\n",
    "- **Train**: 470,858 mẫu\n",
    "- **Validation**: 24,782 mẫu  \n",
    "- **Test**: 3,000 mẫu\n",
    "\n",
    "Mỗi mẫu được mã hóa với `max_length=512`, bao gồm:\n",
    "- `input_ids`: Chuỗi token của prompt + câu nguồn + câu đích\n",
    "- `attention_mask`: Mask phân biệt token thực và padding\n",
    "- `labels`: Copy của `input_ids` để tính loss (Causal Language Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "HF_USERNAME = \"yuiyL\"\n",
    "# Tên Repo Data sẽ đổi theo hướng: ...-tokenized-en-vi HOẶC ...-tokenized-vi-en\n",
    "TOKENIZED_DATASET_REPO = f\"{HF_USERNAME}/qwen2.5-medical-tokenized-{TRAIN_DIRECTION}\"\n",
    "def preprocess(example):\n",
    "    # Đảo chiều input dựa trên cấu hình\n",
    "    if TRAIN_DIRECTION == \"en_vi\":\n",
    "        src, tgt = example[\"en\"], example[\"vi\"]\n",
    "    else: # vi_en\n",
    "        src, tgt = example[\"vi\"], example[\"en\"]\n",
    "\n",
    "    prompt = build_prompt(src, tgt)\n",
    "    tokenized = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "print(f\">>> Checking tokenized dataset: {TOKENIZED_DATASET_REPO}\")\n",
    "\n",
    "try:\n",
    "    tokenized_dataset = load_dataset(TOKENIZED_DATASET_REPO)\n",
    "    print(\"Loaded tokenized dataset from Hub\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Tokenized dataset not found for {TRAIN_DIRECTION}. Running tokenization...\")\n",
    "\n",
    "    tokenized_dataset = raw_dataset.map(\n",
    "        preprocess,\n",
    "        remove_columns=[\"en\", \"vi\"],\n",
    "        desc=f\"Tokenizing medical dataset ({TRAIN_DIRECTION})\"\n",
    "    )\n",
    "\n",
    "    print(\">>> Pushing tokenized dataset to Hub\")\n",
    "    tokenized_dataset.push_to_hub(\n",
    "        TOKENIZED_DATASET_REPO,\n",
    "        private=True\n",
    "    )\n",
    "\n",
    "    print(\"Tokenized dataset uploaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cấu hình LoRA và khởi tạo Training\n",
    "\n",
    "### 7.1. LoRA Configuration\n",
    "\n",
    "**Low-Rank Adaptation (LoRA)** là kỹ thuật PEFT giúp fine-tune mô hình 3B trên GPU 16GB:\n",
    "\n",
    "- **Rank (r=16)**: Kích thước ma trận thích ứng\n",
    "- **Alpha (α=32)**: Hệ số khuếch đại tín hiệu học\n",
    "- **Dropout (0.05)**: Chống overfitting\n",
    "- **Target Modules**: Áp dụng LoRA vào toàn bộ lớp tuyến tính (q, k, v, o, gate, up, down)\n",
    "\n",
    "### 7.2. Safe-Save Protocol\n",
    "\n",
    "Hệ thống kiểm tra Hub để:\n",
    "- **Resume**: Nếu đã có adapter → Tải về và tiếp tục huấn luyện\n",
    "- **Fresh Start**: Nếu chưa có → Khởi tạo LoRA mới\n",
    "\n",
    "File `best_state.json` lưu giá trị `best_eval_loss` để so sánh hiệu năng qua các phiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
    "from peft import LoraConfig, TaskType, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import HfApi, hf_hub_download\n",
    "\n",
    "import gc\n",
    "def reset_cuda():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "HF_USERNAME = \"yuiyL\"\n",
    "# Tên Model cũng đổi theo hướng: ...-sft-en-vi HOẶC ...-sft-vi-en\n",
    "REPO_NAME = f\"qwen2.5-3b-medical-sft-{TRAIN_DIRECTION}\"\n",
    "HUB_MODEL_ID = f\"{HF_USERNAME}/{REPO_NAME}\"\n",
    "\n",
    "OUTPUT_DIR = f\"qwen2.5-3b-medical-sft-{TRAIN_DIRECTION}\"\n",
    "FINAL_ADAPTER_DIR = f\"{OUTPUT_DIR}/final_adapter\"\n",
    "STATE_FILE_NAME = \"best_state.json\"\n",
    "LOCAL_STATE_FILE = f\"{FINAL_ADAPTER_DIR}/{STATE_FILE_NAME}\"\n",
    "os.makedirs(FINAL_ADAPTER_DIR, exist_ok=True)\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "\n",
    "best_prev_loss = float(\"inf\")\n",
    "print(f\">>> Checking Hub history: {HUB_MODEL_ID}\")\n",
    "\n",
    "try:\n",
    "    downloaded_path = hf_hub_download(\n",
    "        repo_id=HUB_MODEL_ID,\n",
    "        filename=STATE_FILE_NAME,\n",
    "        local_dir=FINAL_ADAPTER_DIR\n",
    "    )\n",
    "    with open(downloaded_path, \"r\") as f:\n",
    "        best_prev_loss = json.load(f).get(\"best_eval_loss\", float(\"inf\"))\n",
    "    print(f\"Found previous best loss: {best_prev_loss:.4f}\")\n",
    "except Exception:\n",
    "    print(\"No previous record found. Fresh run.\")\n",
    "\n",
    "\n",
    "peft_config = None\n",
    "has_adapter_on_hub = False\n",
    "\n",
    "try:\n",
    "    if \"adapter_model.safetensors\" in api.list_repo_files(HUB_MODEL_ID):\n",
    "        has_adapter_on_hub = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if has_adapter_on_hub:\n",
    "    print(\">>> RESUME: Loading adapter from Hub\")\n",
    "    model = PeftModel.from_pretrained(model, HUB_MODEL_ID, is_trainable=True)\n",
    "else:\n",
    "    print(\">>> FRESH START: Initializing new LoRA\")\n",
    "    peft_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        target_modules=[\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\",\n",
    "            \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Training Arguments\n",
    "Cell này chứa cấu hình siêu tham số huấn luyện:\n",
    "\n",
    "**Chiến lược đa giai đoạn:**\n",
    "- **Giai đoạn 1 (Khởi đầu)**: 10K mẫu, 800 steps, LR=2e-4\n",
    "- **Giai đoạn 2 (Tinh chỉnh)**: 20K mẫu, 1600 steps, LR=5e-5  \n",
    "- **Giai đoạn 3 (Hội tụ sâu)**: 20K mẫu, 1600 steps, LR=1e-5\n",
    "\n",
    "**Tối ưu hóa VRAM:**\n",
    "- Batch size = 4 (per device)\n",
    "- Gradient accumulation = 4 → Effective batch = 16\n",
    "- Mixed Precision (BF16)\n",
    "\n",
    "**Giám sát:**\n",
    "- Eval every 200 steps\n",
    "- Early Stopping patience = 2\n",
    "- Load best model at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VALID_SIZE = 500\n",
    "TRAIN_SIZE = 20000\n",
    "MAX_STEPS  = 1600\n",
    "EVAL_STEPS = 200\n",
    "\n",
    "train_subset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(TRAIN_SIZE))\n",
    "valid_subset = tokenized_dataset[\"validation\"].select(range(VALID_SIZE))\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    pad_to_multiple_of=8,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\n",
    "    max_steps=MAX_STEPS,               \n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_steps=120,   \n",
    "\n",
    "    per_device_eval_batch_size=2,\n",
    "\n",
    "    eval_strategy=\"steps\",         \n",
    "    eval_steps=EVAL_STEPS,             \n",
    "    save_strategy=\"steps\",             \n",
    "    save_steps=EVAL_STEPS,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Training Execution\n",
    "\n",
    "Cell này thực thi quá trình huấn luyện và áp dụng **Best-Model-Only Policy**:\n",
    "\n",
    "1. **Train**: SFTTrainer huấn luyện với Early Stopping\n",
    "2. **Compare**: So sánh `current_run_best_loss` với `best_prev_loss`\n",
    "3. **Save & Push**: Chỉ cập nhật Hub nếu model mới tốt hơn\n",
    "\n",
    "**Lợi ích:**\n",
    "- Tiết kiệm băng thông (chỉ push checkpoint tốt nhất)\n",
    "- Đảm bảo tính liên tục qua các phiên Kaggle\n",
    "- Tận dụng tối đa 500K mẫu qua nhiều phiên huấn luyện (nhờ shuffle seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_subset,\n",
    "    eval_dataset=valid_subset,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[\n",
    "        # SafeBleuEvalCallback(tokenizer, test_pairs, num_samples=50),\n",
    "        EarlyStoppingCallback(early_stopping_patience=2),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\nReset CUDA before training\")\n",
    "reset_cuda()\n",
    "\n",
    "print(\"\\n>>> START TRAINING\")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "current_run_best_loss = trainer.state.best_metric\n",
    "if current_run_best_loss is None:\n",
    "    current_run_best_loss = trainer.evaluate()[\"eval_loss\"]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Previous best loss : {best_prev_loss:.4f}\")\n",
    "print(f\"Current run loss   : {current_run_best_loss:.4f}\")\n",
    "\n",
    "if current_run_best_loss < best_prev_loss:\n",
    "    print(\"New model is better. Saving & pushing to Hub.\")\n",
    "\n",
    "    trainer.save_model(FINAL_ADAPTER_DIR)\n",
    "    tokenizer.save_pretrained(FINAL_ADAPTER_DIR)\n",
    "\n",
    "    with open(LOCAL_STATE_FILE, \"w\") as f:\n",
    "        json.dump({\"best_eval_loss\": current_run_best_loss}, f)\n",
    "\n",
    "    api.upload_folder(\n",
    "        folder_path=FINAL_ADAPTER_DIR,\n",
    "        repo_id=HUB_MODEL_ID,\n",
    "        repo_type=\"model\",\n",
    "        commit_message=f\"Upgrade: loss {current_run_best_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Updated model: https://huggingface.co/{HUB_MODEL_ID}\")\n",
    "else:\n",
    "    print(\"Model not improved. Skip pushing.\")\n",
    "\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phân tích Learning Curves\n",
    "Do quá trình train không cần thực thi lại nên sẽ viết code để vẽ theo dữ liệu đã được train (ảnh)\n",
    "### Trực quan hóa quá trình học\n",
    "\n",
    "Cell này vẽ đường cong **Training Loss** và **Validation Loss** qua các steps để:\n",
    "\n",
    "#### Nhận diện hội tụ tối ưu:\n",
    "- **EN-VI**: Best model tại Step 1200 (Val Loss = 1.0936)\n",
    "- **VI-EN**: Best model tại Step 1200 (Val Loss = 1.0726)\n",
    "\n",
    "#### Nhận diện Overfitting:\n",
    "- Training Loss giảm mạnh nhưng Validation Loss tăng\n",
    "- Đánh dấu bằng dấu sao vàng (⭐) tại điểm tối ưu\n",
    "\n",
    "**Insight**: Cả hai chiều đều đạt đỉnh hiệu năng tại cùng một checkpoint, chứng minh tính ổn định của cấu hình LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Thiết lập phong cách academic\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "\n",
    "def plot_training_metrics(steps, train_loss, val_loss, title, filename):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    line1, = ax.plot(steps, train_loss, 'b-o', label='Training Loss', linewidth=2, markersize=7, alpha=0.7)\n",
    "    line2, = ax.plot(steps, val_loss, 'r-s', label='Validation Loss', linewidth=2, markersize=7, alpha=0.7)\n",
    "    \n",
    "    for i, (s, tl, vl) in enumerate(zip(steps, train_loss, val_loss)):\n",
    "        ax.text(s, tl + 0.005, f'{tl:.3f}', color='blue', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        ax.text(s, vl - 0.005, f'{vl:.3f}', color='red', ha='center', va='top', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    min_val_loss = min(val_loss)\n",
    "    idx_min = val_loss.index(min_val_loss)\n",
    "    best_step = steps[idx_min]\n",
    "    \n",
    "    ax.scatter(best_step, min_val_loss, color='gold', s=350, marker='*', \n",
    "               edgecolors='black', zorder=10, label=f'Best Model')\n",
    "    \n",
    "    ax.annotate(f'BEST: {min_val_loss:.4f}', \n",
    "                xy=(best_step, min_val_loss),\n",
    "                xytext=(0, -35), \n",
    "                textcoords='offset points',\n",
    "                ha='center',\n",
    "                fontsize=11, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", ec=\"black\", alpha=0.8))\n",
    "\n",
    "    ax.set_title(title, fontsize=18, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Training Steps', fontsize=13)\n",
    "    ax.set_ylabel('Loss (Cross Entropy)', fontsize=13)\n",
    "    \n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0, frameon=True, shadow=True)\n",
    "    \n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# EN-VI\n",
    "steps_envi_good = [200, 400, 600, 800, 1000, 1200, 1400, 1600]\n",
    "train_envi_good = [1.1528, 1.1285, 1.1191, 1.1227, 1.1070, 1.1212, 1.0142, 1.0165]\n",
    "val_envi_good = [1.1326, 1.1247, 1.1143, 1.1059, 1.0993, 1.0936, 1.0971, 1.0972]\n",
    "\n",
    "steps_envi_over = [200, 400, 600]\n",
    "train_envi_over = [0.8120, 0.7886, 0.8186]\n",
    "val_envi_over = [1.0902, 1.1021, 1.0920]\n",
    "\n",
    "# VI-EN\n",
    "steps_vien_good = [200, 400, 600, 800, 1000, 1200, 1400, 1600]\n",
    "train_vien_good = [1.1258, 1.0915, 1.0821, 1.0857, 1.0700, 1.0842, 0.9772, 0.9795]\n",
    "val_vien_good = [1.1116, 1.1037, 1.0933, 1.0849, 1.0783, 1.0726, 1.0762, 1.0763]\n",
    "\n",
    "steps_vien_bad = [200, 400, 600]\n",
    "train_vien_bad = [1.0170, 0.9919, 0.9928]\n",
    "val_vien_bad = [1.0982, 1.1022, 1.1034]\n",
    "\n",
    "plot_training_metrics(steps_envi_good, train_envi_good, val_envi_good, \"EN-VI Translation: Optimal Convergence\", \"envi_good_v2.png\")\n",
    "plot_training_metrics(steps_envi_over, train_envi_over, val_envi_over, \"EN-VI Translation: Overfitting Analysis\", \"envi_overfit_v2.png\")\n",
    "plot_training_metrics(steps_vien_good, train_vien_good, val_vien_good, \"VI-EN Translation: Optimal Convergence\", \"vien_good_v2.png\")\n",
    "plot_training_metrics(steps_vien_bad, train_vien_bad, val_vien_bad, \"VI-EN Translation: Non-improving Scenario\", \"vien_bad_v2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Đánh giá định lượng (Sacre BLEU Score)\n",
    "\n",
    "### 9.1. Cấu hình Đánh giá\n",
    "\n",
    "- **UPDATE_ALL_TEST = True**: Dịch lại toàn bộ 3000 câu test bằng model hiện tại\n",
    "- **UPDATE_ALL_TEST = False**: Chỉ load kết quả dịch đã lưu trên Hub\n",
    "\n",
    "**Lưu trữ:** trên Hugging Face Hub\n",
    "- `test_results_en_vi.parquet`: Kết quả dịch EN→VI\n",
    "- `test_results_vi_en.parquet`: Kết quả dịch VI→EN\n",
    "\n",
    "Mỗi file chứa:\n",
    "- `source`: Câu nguồn\n",
    "- `reference`: Ground truth\n",
    "- `base_model`: Bản dịch của Base Model (zero-shot)\n",
    "- `fine_tuned`: Bản dịch của Fine-tuned Model (LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CẤU HÌNH ĐÁNH GIÁ CHIẾN LƯỢC ---\n",
    "UPDATE_ALL_TEST = True  # True: Dịcah lại 3000 câu bằng model hiện tại | False: Chỉ load file cũ\n",
    "TEST_REPO_ID = f\"{HF_USERNAME}/medical-test-results\" # Tên repo chứa kết quả dịch\n",
    "\n",
    "# Tên file cho từng chiều\n",
    "FILE_EN_VI = \"test_results_en_vi.parquet\"\n",
    "FILE_VI_EN = \"test_results_vi_en.parquet\"\n",
    "\n",
    "print(f\">>> Hướng huấn luyện chính: {TRAIN_DIRECTION.upper()}\")\n",
    "print(f\">>> Chế độ cập nhật: {'BẮT ĐẦU DỊCH VÀ GHI ĐÈ' if UPDATE_ALL_TEST else 'CHỈ LOAD DỮ LIỆU ĐÃ LƯU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Inference và Lưu trữ Kết quả\n",
    "\n",
    "#### Quy trình:\n",
    "1. **Check Hub**: Kiểm tra file kết quả có tồn tại chưa\n",
    "2. **Translate**: Nếu `UPDATE_ALL_TEST=True`, dịch toàn bộ 3000 mẫu:\n",
    "   - **Base Model**: Tắt adapter (`model.disable_adapter()`)\n",
    "   - **Fine-tuned Model**: Bật adapter (mặc định)\n",
    "3. **Save & Upload**: Lưu DataFrame → Parquet → Push lên Hub\n",
    "\n",
    "**Lợi ích:**\n",
    "- Tránh inference lặp lại (tiết kiệm ~30 phút GPU)\n",
    "- Cho phép phân tích offline sau khi Kernel dừng\n",
    "- Dễ dàng so sánh giữa các phiên bản model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from huggingface_hub import hf_hub_download, upload_file\n",
    "from tqdm import tqdm\n",
    "import sacrebleu\n",
    "\n",
    "def get_or_update_translations(model, tokenizer, dataset, direction, update=False):\n",
    "    filename = FILE_EN_VI if direction == \"en_vi\" else FILE_VI_EN\n",
    "    df_results = None\n",
    "    \n",
    "    try:\n",
    "        path = hf_hub_download(repo_id=TEST_REPO_ID, filename=filename, repo_type=\"dataset\")\n",
    "        df_results = pd.read_parquet(path)\n",
    "        print(f\"Đã tải file kết quả cũ của {direction.upper()} ({len(df_results)} câu)\")\n",
    "    except:\n",
    "        print(f\"ℹChưa có dữ liệu cũ cho chiều {direction.upper()} trên Hub.\")\n",
    "\n",
    "    # Nếu update=True hoặc chưa có file -> Thực hiện dịch\n",
    "    if update or df_results is None:\n",
    "        print(f\"Đang tiến hành dịch 3000 câu cho chiều {direction.upper()}...\")\n",
    "        src_key = \"en\" if direction == \"en_vi\" else \"vi\"\n",
    "        tgt_key = \"vi\" if direction == \"en_vi\" else \"en\"\n",
    "        prompt_tpl = \"Dịch câu sau sang tiếng Việt:\\n{}\" if direction == \"en_vi\" else \"Dịch câu sau sang tiếng Anh:\\n{}\"\n",
    "        \n",
    "        # Lấy toàn bộ 3000 mẫu\n",
    "        samples = dataset.select(range(min(3000, len(dataset))))\n",
    "        data = {\"source\": [], \"reference\": [], \"base_model\": [], \"fine_tuned\": []}\n",
    "\n",
    "        model.eval()\n",
    "        for item in tqdm(samples, desc=f\"Translating {direction.upper()}\"):\n",
    "            src_text, ref_text = item[src_key], item[tgt_key]\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt_tpl.format(src_text)}]\n",
    "            inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Dịch bằng Base Model (Tắt adapter)\n",
    "                with model.disable_adapter():\n",
    "                    out_base = model.generate(inputs, max_new_tokens=512, do_sample=False)\n",
    "                    data[\"base_model\"].append(tokenizer.decode(out_base[0][len(inputs[0]):], skip_special_tokens=True).strip())\n",
    "                \n",
    "                # Dịch bằng Fine-tuned Model (Bật adapter)\n",
    "                out_ft = model.generate(inputs, max_new_tokens=512, do_sample=False)\n",
    "                data[\"fine_tuned\"].append(tokenizer.decode(out_ft[0][len(inputs[0]):], skip_special_tokens=True).strip())\n",
    "            \n",
    "        df_results = pd.DataFrame(data)\n",
    "        \n",
    "        # Lưu và đẩy lên Hub ngay lập tức\n",
    "        df_results.to_parquet(filename)\n",
    "        upload_file(path_or_fileobj=filename, path_in_repo=filename, repo_id=TEST_REPO_ID, repo_type=\"dataset\")\n",
    "        print(f\"Đã cập nhật và upload kết quả mới cho {direction.upper()}.\")\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# Thực thi cập nhật cho hướng hiện tại\n",
    "test_data = raw_dataset[\"test\"]\n",
    "# Hàm này sẽ chỉ dịch nếu UPDATE_ALL_TEST = True, nếu không nó chỉ load df_results\n",
    "current_df = get_or_update_translations(model, tokenizer, test_data, TRAIN_DIRECTION, update=UPDATE_ALL_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Tính toán và Báo cáo BLEU\n",
    "\n",
    "Cell này tải kết quả từ Hub và tính **SacreBLEU** cho cả hai chiều:\n",
    "\n",
    "#### Output mẫu:\n",
    "```\n",
    "| Direction |   BASE   | FINE-TUNED | Improvement|\n",
    "|-----------|----------|------------|------------|\n",
    "| EN -> VI  |   45.23  |      52.67 |      +7.44 |\n",
    "| VI -> EN  |   48.91  |      55.12 |      +6.21 |\n",
    "```\n",
    "\n",
    "**Giải thích:**\n",
    "- Cải thiện đáng kể (~6-7 điểm BLEU) chứng minh hiệu quả của LoRA fine-tuning\n",
    "- Điểm VI→EN thường cao hơn do tiếng Anh y khoa có tính khuôn mẫu cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_from_df(df):\n",
    "    if df is None: return 0.0, 0.0\n",
    "    refs = [df[\"reference\"].tolist()]\n",
    "    b_base = sacrebleu.corpus_bleu(df[\"base_model\"].tolist(), refs).score\n",
    "    b_ft = sacrebleu.corpus_bleu(df[\"fine_tuned\"].tolist(), refs).score\n",
    "    return b_base, b_ft\n",
    "\n",
    "def full_report():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"BÁO CÁO SO SÁNH HIỆU NĂNG (DỰA TRÊN DỮ LIỆU ĐÃ LƯU)\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Load file EN->VI\n",
    "    try:\n",
    "        path_en_vi = hf_hub_download(repo_id=TEST_REPO_ID, filename=FILE_EN_VI, repo_type=\"dataset\")\n",
    "        df_en_vi = pd.read_parquet(path_en_vi)\n",
    "        base_en_vi, ft_en_vi = calculate_bleu_from_df(df_en_vi)\n",
    "    except:\n",
    "        base_en_vi, ft_en_vi = 0, 0\n",
    "\n",
    "    # Load file VI->EN\n",
    "    try:\n",
    "        path_vi_en = hf_hub_download(repo_id=TEST_REPO_ID, filename=FILE_VI_EN, repo_type=\"dataset\")\n",
    "        df_vi_en = pd.read_parquet(path_vi_en)\n",
    "        base_vi_en, ft_vi_en = calculate_bleu_from_df(df_vi_en)\n",
    "    except:\n",
    "        base_vi_en, ft_vi_en = 0, 0\n",
    "\n",
    "    # In bảng kết quả giống hệt format cũ của bạn\n",
    "    print(f\"| Direction |   BASE   | FINE-TUNED | Improvement|\")\n",
    "    print(\"|-----------|----------|------------|------------|\")\n",
    "    \n",
    "    imp_en_vi = ft_en_vi - base_en_vi\n",
    "    print(f\"| EN -> VI  | {base_en_vi:8.2f} | {ft_en_vi:10.2f} | {imp_en_vi:10.2f} |\")\n",
    "    \n",
    "    imp_vi_en = ft_vi_en - base_vi_en\n",
    "    print(f\"| VI -> EN  | {base_vi_en:8.2f} | {ft_vi_en:10.2f} | {imp_vi_en:10.2f} |\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "full_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Đánh giá Định tính (Gemini Score)\n",
    "\n",
    "### Cài đặt Google Gemini API\n",
    "Nâng cấp thư viện `google-genai` để sử dụng Gemini làm LLM-as-a-Judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U google-genai sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1. Chuẩn bị API Keys\n",
    "\n",
    "Sử dụng **8 API keys** để xoay vòng khi gặp giới hạn rate limit (429 error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "from google import genai\n",
    "from tqdm import tqdm\n",
    "import sacrebleu\n",
    "\n",
    "test_data = raw_dataset[\"test\"]\n",
    "\n",
    "API_KEYS = [\"API KEY\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Hàm Chấm điểm Song song (Dual Scoring)\n",
    "\n",
    "#### Tiêu chí Đánh giá (0-100 điểm):\n",
    "\n",
    "1. **Độ chính xác y khoa (50%)**:\n",
    "   - Sai thuật ngữ/liều lượng: -40 điểm\n",
    "   - Bỏ sót thông tin quan trọng: -20 điểm\n",
    "\n",
    "2. **Thuật ngữ chuyên ngành (30%)**:\n",
    "   - Ưu tiên từ chuyên môn hơn từ phổ thông\n",
    "\n",
    "3. **Văn phong & Tính lưu loát (20%)**:\n",
    "   - Văn phong trung lập, khoa học\n",
    "   - Không chứa câu dẫn (\"Here is the translation...\")\n",
    "\n",
    "#### Cơ chế Fallback:\n",
    "- Ưu tiên `gemini-2.0-flash`\n",
    "- Nếu 404 → Chuyển sang `gemini-2.0-flash-lite`\n",
    "- Nếu 429 (hết quota) → Đổi API key và retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dual_gemini_scores(batch_items, api_keys, api_idx, src_lang, tgt_lang):\n",
    "    \"\"\"\n",
    "    Chấm điểm song song Base vs FT với cơ chế đổi Key và Fallback Model.\n",
    "    \"\"\"\n",
    "    # Lấy Key hiện tại dựa trên api_idx\n",
    "    current_key = api_keys[api_idx % len(api_keys)]\n",
    "    client = genai.Client(api_key=current_key)\n",
    "    \n",
    "    num_items = len(batch_items)\n",
    "    items_prompt = \"\"\n",
    "    for idx, item in enumerate(batch_items):\n",
    "        items_prompt += f\"\"\"\n",
    "--- Cặp {idx+1} ---\n",
    "Gốc: {item['src']}\n",
    "Tham chiếu: {item['ref']}\n",
    "Bản dịch A (Base): {item['base']}\n",
    "Bản dịch B (Fine-tuned): {item['ft']}\n",
    "\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Bạn là một chuyên gia thẩm định dịch thuật Y khoa (Medical Translation Evaluator).\n",
    "    \n",
    "        Nhiệm vụ của bạn là đánh giá hai bản dịch từ {src_lang} sang {tgt_lang}:\n",
    "        - Bản dịch A: Base model\n",
    "        - Bản dịch B: Fine-tuned model\n",
    "        \n",
    "        Việc đánh giá phải dựa trên câu tham chiếu và tập trung vào tính an toàn y khoa.\n",
    "        \n",
    "        ### TIÊU CHÍ CHẤM ĐIỂM (0–100):\n",
    "        1. Độ chính xác y khoa (50%):\n",
    "           - Sai thuật ngữ bệnh, thuốc, liều lượng hoặc chỉ dẫn lâm sàng → trừ ≥40 điểm.\n",
    "           - Bỏ sót thông tin y khoa quan trọng (omission) → trừ ≥20 điểm.\n",
    "        \n",
    "        2. Thuật ngữ chuyên ngành (30%):\n",
    "           - Ưu tiên thuật ngữ y khoa chuẩn, nhất quán.\n",
    "           - Dùng từ phổ thông thay cho thuật ngữ chuyên môn → trừ điểm.\n",
    "        \n",
    "        3. Văn phong & tính lưu loát (20%):\n",
    "           - Văn phong trung lập, khoa học.\n",
    "           - Không chứa câu dẫn như \"Here is the translation\".\n",
    "        \n",
    "        ### QUY TẮC TRỪ ĐIỂM CỨNG:\n",
    "        - Trừ 10 điểm: Có câu dẫn hoặc bình luận ngoài nội dung dịch.\n",
    "        - Trừ 40 điểm: Lỗi nghiêm trọng ảnh hưởng an toàn y tế.\n",
    "        - Trừ 20 điểm: Cấu trúc danh từ y khoa gây mơ hồ nghĩa.\n",
    "        \n",
    "        ### ĐỊNH DẠNG TRẢ VỀ (CHỈ JSON):\n",
    "        {{\n",
    "          \"results\": [\n",
    "            {{\n",
    "              \"base_score\": int,\n",
    "              \"ft_score\": int,\n",
    "              \"reason\": \"Nhận xét ngắn gọn, tập trung vào lỗi hoặc ưu điểm y khoa\"\n",
    "            }}\n",
    "          ]\n",
    "        }}\n",
    "        \n",
    "        Dữ liệu cần chấm điểm:\n",
    "    {items_prompt}\"\"\"\n",
    "\n",
    "    # Danh sách model ứng viên theo thứ tự ưu tiên\n",
    "    model_candidates = [\n",
    "        \"models/gemini-2.0-flash\", \n",
    "        \"models/gemini-2.0-flash-lite\"\n",
    "    ]\n",
    "\n",
    "    for model_id in model_candidates:\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model_id,\n",
    "                contents=prompt\n",
    "            )\n",
    "            text = response.text.strip()\n",
    "            \n",
    "            # Làm sạch JSON từ markdown\n",
    "            if \"```json\" in text:\n",
    "                text = text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            elif \"```\" in text:\n",
    "                text = text.replace(\"```\", \"\").strip()\n",
    "            \n",
    "            data = json.loads(text)\n",
    "            results = data.get(\"results\", [])\n",
    "            \n",
    "            if len(results) == num_items:\n",
    "                return results, api_idx + 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            if \"404\" in str(e):\n",
    "                continue # Thử model tiếp theo\n",
    "            elif \"429\" in str(e):\n",
    "                # Hết quota -> Đổi Key ngay lập tức và đệ quy lại với chính batch này\n",
    "                print(f\"Key {api_idx % len(api_keys)} hết hạn mức. Đang đổi sang Key tiếp theo...\")\n",
    "                return get_dual_gemini_scores(batch_items, api_keys, api_idx + 1, src_lang, tgt_lang)\n",
    "            else:\n",
    "                print(f\"Lỗi không xác định: {e}\")\n",
    "                break\n",
    "                \n",
    "    return [{\"base_score\": None, \"ft_score\": None, \"reason\": \"Error\"}] * num_items, api_idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3. Thực thi Đánh giá Gemini\n",
    "\n",
    "#### Quy trình:\n",
    "1. **Lọc**: Chọn 50 câu có độ dài ≥15 từ (câu phức tạp, giàu thuật ngữ)\n",
    "2. **Batch Scoring**: Chấm điểm theo lô 4 mẫu/lần\n",
    "3. **Lưu trữ**: Lưu DataFrame đầy đủ (gồm source, reference, base, ft, scores, reason) lên Hub\n",
    "\n",
    "#### Output:\n",
    "- `base_score`: Điểm Base Model\n",
    "- `ft_score`: Điểm Fine-tuned Model\n",
    "- `reason`: Nhận xét chi tiết của Gemini về lỗi/ưu điểm\n",
    "\n",
    "**Kết quả mẫu:**\n",
    "```\n",
    "✅ Đánh giá xong! Trung bình Base: 72.35 | FT: 85.12\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gemini_comparison_eval(num_samples=100, min_words=15):\n",
    "    # 1. Load dữ liệu đã dịch sẵn từ Hub\n",
    "    filename = FILE_EN_VI if TRAIN_DIRECTION == \"en_vi\" else FILE_VI_EN\n",
    "    try:\n",
    "        path = hf_hub_download(repo_id=TEST_REPO_ID, filename=filename, repo_type=\"dataset\")\n",
    "        df = pd.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Không tìm thấy file dữ liệu: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Lọc các câu có độ dài >= min_words (tính theo số từ)\n",
    "    # Điều này giúp đánh giá các câu phức hợp, mang tính chuyên môn cao hơn\n",
    "    df_filtered = df[df['source'].str.split().str.len() >= min_words].copy()\n",
    "    \n",
    "    if len(df_filtered) < num_samples:\n",
    "        print(f\"Chỉ tìm thấy {len(df_filtered)} câu thỏa mãn độ dài >= {min_words}. Sẽ dùng toàn bộ.\")\n",
    "        num_samples = len(df_filtered)\n",
    "\n",
    "    # Lấy mẫu ngẫu nhiên từ danh sách đã lọc\n",
    "    sampled_df = df_filtered.sample(n=num_samples, random_state=42).copy()\n",
    "    \n",
    "    src_lang = \"Tiếng Anh\" if TRAIN_DIRECTION == \"en_vi\" else \"Tiếng Việt\"\n",
    "    tgt_lang = \"Tiếng Việt\" if TRAIN_DIRECTION == \"en_vi\" else \"Tiếng Anh\"\n",
    "    \n",
    "    items_to_score = []\n",
    "    for _, row in sampled_df.iterrows():\n",
    "        items_to_score.append({\n",
    "            \"src\": row[\"source\"], \"ref\": row[\"reference\"], \n",
    "            \"base\": row[\"base_model\"], \"ft\": row[\"fine_tuned\"]\n",
    "        })\n",
    "\n",
    "    all_results = []\n",
    "    api_idx = 0\n",
    "    batch_size = 4 \n",
    "\n",
    "    print(f\"Đang chấm điểm {len(items_to_score)} câu (Độ dài >= {min_words} từ)...\")\n",
    "    for i in tqdm(range(0, len(items_to_score), batch_size), desc=\"Gemini Comparison\"):\n",
    "        batch = items_to_score[i:i+batch_size]\n",
    "        results, api_idx = get_dual_gemini_scores(batch, API_KEYS, api_idx, src_lang, tgt_lang)\n",
    "        all_results.extend(results)\n",
    "        time.sleep(4)\n",
    "\n",
    "    # Tổng hợp tất cả thông tin vào DataFrame\n",
    "    # Cột đã có: source, reference, base_model, fine_tuned\n",
    "    # Cột thêm mới:\n",
    "    sampled_df[\"base_score\"] = [r.get(\"base_score\") for r in all_results]\n",
    "    sampled_df[\"ft_score\"] = [r.get(\"ft_score\") for r in all_results]\n",
    "    sampled_df[\"reason\"] = [r.get(\"reason\") for r in all_results]\n",
    "\n",
    "    # In kết quả tổng quát\n",
    "    avg_base = sampled_df[\"base_score\"].dropna().mean()\n",
    "    avg_ft = sampled_df[\"ft_score\"].dropna().mean()\n",
    "    print(f\"\\nĐánh giá xong! Trung bình Base: {avg_base:.2f} | FT: {avg_ft:.2f}\")\n",
    "\n",
    "    # Lưu file eval chi tiết (chứa mọi cột) lên Hub\n",
    "    eval_file = f\"gemini_dual_eval_{TRAIN_DIRECTION}.parquet\"\n",
    "    sampled_df.to_parquet(eval_file)\n",
    "    upload_file(path_or_fileobj=eval_file, path_in_repo=eval_file, repo_id=TEST_REPO_ID, repo_type=\"dataset\")\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "# Thực thi\n",
    "df_comparison = run_gemini_comparison_eval(num_samples=50, min_words=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Demo Dịch Thuật Trực tiếp\n",
    "\n",
    "### So sánh Base Model vs Fine-tuned Model\n",
    "\n",
    "Cell này cho phép kiểm thử nhanh với một câu cụ thể:\n",
    "\n",
    "#### Ví dụ:\n",
    "**Input (VI):**\n",
    "> \"Nghiên cứu được thực hiện nhằm đánh giá tác dụng giảm cân, hạ lipid máu của hỗn hợp dịch chiết lá Trà hoa vàng và Giảo cổ lam trên chuột nhắt trắng gây béo phì.\"\n",
    "\n",
    "**Output (EN):**\n",
    "- **Base Model**: Bản dịch chưa tối ưu, có thể thiếu thuật ngữ chính xác\n",
    "- **Fine-tuned Model**: Bản dịch chính xác, sử dụng thuật ngữ khoa học chuẩn\n",
    "\n",
    "#### Tham số:\n",
    "- `target_lang=\"en\"`: Dịch sang tiếng Anh\n",
    "- `target_lang=\"vi\"`: Dịch sang tiếng Việt\n",
    "- `temperature=0.3`: Giảm randomness, tăng tính nhất quán\n",
    "- `repetition_penalty=1.1`: Tránh lặp từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "# dịch 1 ví dụ\n",
    "def translate_wrapper(text, model, tokenizer, label=\"\", target_lang=\"en\"):\n",
    "    \"\"\"\n",
    "    target_lang=\"vi\" -> Dịch sang Tiếng Việt\n",
    "    target_lang=\"en\" -> Dịch sang Tiếng Anh\n",
    "    \"\"\"\n",
    "    \n",
    "    if target_lang == \"en\":\n",
    "        prompt = f\"Dịch câu sau sang tiếng Anh:\\n{text}\"\n",
    "    else:\n",
    "        prompt = f\"Dịch câu sau sang tiếng Việt:\\n{text}\"\n",
    "        \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_new_tokens=512,\n",
    "            temperature=0.3,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1\n",
    "        )\n",
    "    \n",
    "    generated_ids = outputs[0][len(inputs[0]):]\n",
    "    result = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"[{label}]: {result}\")\n",
    "    return result\n",
    "\n",
    "def compare_models(text_input, model, tokenizer, target_lang=\"en\"):\n",
    "    direction = \"VIỆT -> ANH\" if target_lang == \"en\" else \"ANH -> VIỆT\"\n",
    "    print(f\"Input ({direction}): {text_input}\\n\" + \"-\"*50)\n",
    "    \n",
    "    print(\">>> 1. Model Gốc (Base Model):\")\n",
    "    with model.disable_adapter():\n",
    "        old_pred = translate_wrapper(text_input, model, tokenizer, label=\"Old\", target_lang=target_lang)\n",
    "        \n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(\">>> 2. Model Mới (Fine-tuned):\")\n",
    "    new_pred = translate_wrapper(text_input, model, tokenizer, label=\"New\", target_lang=target_lang)\n",
    "    \n",
    "    print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "sample_vi = \"Nghiên cứu được thực hiện nhằm đánh giá tác dụng giảm cân, hạ lipid máu của hỗn hợp dịch chiết lá Trà hoa vàng và Giảo cổ lam trên chuột nhắt trắng gây béo phì.\"\n",
    "sample_en = \"The purpose of this study was to evaluate the effects of a mixture extract of C chrysantha and G pentaphyllum on weight loss and lowering lipid blood levels in obese Swiss mice.\"\n",
    "\n",
    "\n",
    "print(f\"Reference English: {sample_en}\\n\")\n",
    "\n",
    "# Gọi hàm với tham số target_lang=\"en\"\n",
    "compare_models(sample_vi, model, tokenizer, target_lang=\"en\")\n",
    "# Gọi hàm với tham số target_lang=\"vi\"\n",
    "compare_models(sample_en, model, tokenizer, target_lang=\"vi\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9033470,
     "sourceId": 14172024,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
